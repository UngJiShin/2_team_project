{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e89c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb9925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "381d131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"root\"\n",
    "password = \"1234\"   \n",
    "host = \"localhost\"      \n",
    "port = 3306             \n",
    "database = \"manufacturing_insight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9786cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://root:1234@127.0.0.1:3306/manufacturing_insight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9087dc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>email</th>\n",
       "      <th>password_hash</th>\n",
       "      <th>name</th>\n",
       "      <th>login_type</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, email, password_hash, name, login_type, created_at]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM users;\", engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b78e62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>region_code</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>production_index</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, date, region_code, industry_code, production_index, updated_at]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(\"SELECT * FROM production_index LIMIT 5;\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e471434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>region</th>\n",
       "      <th>division</th>\n",
       "      <th>client_num</th>\n",
       "      <th>power_kwh</th>\n",
       "      <th>price</th>\n",
       "      <th>mean_price_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>산업용</td>\n",
       "      <td>7,183</td>\n",
       "      <td>412,125,715</td>\n",
       "      <td>24,277,829,834</td>\n",
       "      <td>58.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>합계</td>\n",
       "      <td>678,266</td>\n",
       "      <td>980,802,845</td>\n",
       "      <td>63,944,459,370</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>산업용</td>\n",
       "      <td>75,741</td>\n",
       "      <td>2,348,126,225</td>\n",
       "      <td>151,019,627,510</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>합계</td>\n",
       "      <td>2,675,136</td>\n",
       "      <td>4,788,402,685</td>\n",
       "      <td>364,271,785,816</td>\n",
       "      <td>76.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>경남</td>\n",
       "      <td>산업용</td>\n",
       "      <td>25,011</td>\n",
       "      <td>1,054,021,417</td>\n",
       "      <td>67,625,190,928</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month region division  client_num       power_kwh             price  \\\n",
       "0  2002-01-01     강원      산업용      7,183     412,125,715    24,277,829,834    \n",
       "1  2002-01-01     강원       합계    678,266     980,802,845    63,944,459,370    \n",
       "2  2002-01-01     경기      산업용     75,741   2,348,126,225   151,019,627,510    \n",
       "3  2002-01-01     경기       합계  2,675,136   4,788,402,685   364,271,785,816    \n",
       "4  2002-01-01     경남      산업용     25,011   1,054,021,417    67,625,190,928    \n",
       "\n",
       "   mean_price_kwh  \n",
       "0            58.9  \n",
       "1            65.2  \n",
       "2            64.3  \n",
       "3            76.1  \n",
       "4            64.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power = pd.read_excel(\"C:/2nd/data/filtered_power_data.xlsx\")  # openpyxl 엔진 자동 인식\n",
    "df_power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "124f5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9070"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power.to_sql(name=\"filtered_power_data\", con=engine, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13be9a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C:/2nd/data/month_city_power_kwh_data.xlsx → month_city_power_kwh_data 테이블로 업로드 완료\n",
      "✅ C:/2nd/data/trimmed_export_amount_data.xlsx → amount_data 테이블로 업로드 완료\n"
     ]
    }
   ],
   "source": [
    "file_table_map = {\n",
    "    \"C:/2nd/data/month_city_power_kwh_data.xlsx\": \"month_city_power_kwh_data\",\n",
    "    \"C:/2nd/data/trimmed_export_amount_data.xlsx\": \"amount_data\"\n",
    "}\n",
    "\n",
    "for file, table in file_table_map.items():\n",
    "    df = pd.read_excel(file)\n",
    "    df.to_sql(name=table, con=engine, index=False, if_exists=\"replace\")\n",
    "    print(f\"✅ {file} → {table} 테이블로 업로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c0b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C:/2nd/data/trimmed_power_kwh_data.xlsx → power_kwh_data 테이블로 업로드 완료\n",
      "✅ C:/2nd/data/trimmed_precipitation_data.xlsx → precipitation_data 테이블로 업로드 완료\n",
      "✅ C:/2nd/data/trimmed_prod_index_data.xlsx → prod_index_data 테이블로 업로드 완료\n",
      "✅ C:/2nd/data/trimmed_temperature_data.xlsx → temp_data 테이블로 업로드 완료\n",
      "✅ C:/2nd/data/year_month_util_rate.xlsx → month_util_rate 테이블로 업로드 완료\n"
     ]
    }
   ],
   "source": [
    "file_table_map = {\n",
    "    \"C:/2nd/data/trimmed_power_kwh_data.xlsx\": \"power_kwh_data\",\n",
    "    \"C:/2nd/data/trimmed_precipitation_data.xlsx\": \"precipitation_data\",\n",
    "    \"C:/2nd/data/trimmed_prod_index_data.xlsx\": \"prod_index_data\",\n",
    "    \"C:/2nd/data/trimmed_temperature_data.xlsx\": \"temp_data\",\n",
    "    \"C:/2nd/data/year_month_util_rate.xlsx\": \"month_util_rate\"\n",
    "}\n",
    "\n",
    "for file, table in file_table_map.items():\n",
    "    df = pd.read_excel(file)\n",
    "    df.to_sql(name=table, con=engine, index=False, if_exists=\"replace\")\n",
    "    print(f\"✅ {file} → {table} 테이블로 업로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425fe94",
   "metadata": {},
   "source": [
    "가설 1: 전력 사용량 패턴과 제조업 생산지수 간의 시간적 관계를 분석하면, 생산 스케줄 예측 및 최적화가 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75e5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63f1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 전력 패턴 기반 제조업 생산지수 예측 분석 ===\n",
      "\n",
      "1. 데이터 로드 중...\n",
      "2. 전력 사용 패턴 분석 중...\n",
      "3. 시간적 관계 분석용 데이터 준비 중...\n",
      "4. 예측 모델 학습 중...\n",
      "5. 시간적 관계 분석 중...\n",
      "6. 결과 시각화 중...\n",
      "7. 생산 스케줄 최적화 인사이트 생성 중...\n",
      "\n",
      "=== 분석 완료 ===\n",
      "실제 데이터를 로드하여 실행하세요!\n"
     ]
    }
   ],
   "source": [
    "class PowerProductionAnalyzer:\n",
    "    def __init__(self, connection_string):\n",
    "        self.engine = create_engine(connection_string)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.models = {}    \n",
    "    def load_and_merge_data(self):\n",
    "        \"\"\"전력 데이터와 생산지수 데이터 통합 로드\"\"\"\n",
    "        # 전력 데이터 로드\n",
    "        power_query = \"\"\"\n",
    "        SELECT \n",
    "            DATE(datetime) as date,\n",
    "            HOUR(datetime) as hour,\n",
    "            city,\n",
    "            AVG(power_kwh) as avg_power,\n",
    "            SUM(power_kwh) as total_power,\n",
    "            COUNT(*) as data_points\n",
    "        FROM filtered_power_data \n",
    "        GROUP BY DATE(datetime), HOUR(datetime), city\n",
    "        ORDER BY date, hour, city\n",
    "        \"\"\"\n",
    "        \n",
    "        # 생산지수 데이터 로드\n",
    "        production_query = \"\"\"\n",
    "        SELECT \n",
    "            DATE(month) as date,\n",
    "            production_index,\n",
    "            industry_type\n",
    "        FROM trimmed_prod_index_data\n",
    "        ORDER BY date\n",
    "        \"\"\"\n",
    "        \n",
    "        power_df = pd.read_sql(power_query, self.engine)\n",
    "        production_df = pd.read_sql(production_query, self.engine)\n",
    "        \n",
    "        return power_df, production_df\n",
    "    \n",
    "    def extract_power_patterns(self, power_df):\n",
    "        \"\"\"전력 사용 패턴 특성 추출\"\"\"\n",
    "        pattern_features = []\n",
    "        \n",
    "        for city in power_df['city'].unique():\n",
    "            city_data = power_df[power_df['city'] == city].copy()\n",
    "            city_data['datetime'] = pd.to_datetime(city_data['date']) + pd.to_timedelta(city_data['hour'], unit='h')\n",
    "            city_data = city_data.set_index('datetime')\n",
    "            \n",
    "            # 일별 집계\n",
    "            daily_data = city_data.groupby(city_data.index.date).agg({\n",
    "                'total_power': 'sum',\n",
    "                'avg_power': 'mean'\n",
    "            }).reset_index()\n",
    "            daily_data.columns = ['date', 'daily_total_power', 'daily_avg_power']\n",
    "            daily_data['date'] = pd.to_datetime(daily_data['date'])\n",
    "            \n",
    "            # 1. 시간대별 패턴 분석\n",
    "            hourly_pattern = city_data.groupby('hour')['avg_power'].mean()\n",
    "            \n",
    "            # 피크 시간대 식별\n",
    "            peaks, _ = find_peaks(hourly_pattern.values, height=hourly_pattern.mean())\n",
    "            peak_hours = hourly_pattern.index[peaks].tolist()\n",
    "            \n",
    "            # 2. 생산 스케줄 관련 특성 추출\n",
    "            for _, day_data in daily_data.iterrows():\n",
    "                date = day_data['date']\n",
    "                \n",
    "                # 해당 날짜의 시간별 데이터\n",
    "                day_hourly = city_data[city_data.index.date == date.date()]\n",
    "                \n",
    "                if len(day_hourly) < 20:  # 데이터가 충분하지 않은 경우 스킵\n",
    "                    continue\n",
    "                \n",
    "                features = {\n",
    "                    'date': date,\n",
    "                    'city': city,\n",
    "                    'total_daily_power': day_data['daily_total_power'],\n",
    "                    'avg_daily_power': day_data['daily_avg_power'],\n",
    "                    \n",
    "                    # 생산 스케줄 관련 특성\n",
    "                    'morning_rush_power': day_hourly[(day_hourly.index.hour >= 7) & (day_hourly.index.hour <= 9)]['avg_power'].mean(),\n",
    "                    'afternoon_peak_power': day_hourly[(day_hourly.index.hour >= 14) & (day_hourly.index.hour <= 16)]['avg_power'].mean(),\n",
    "                    'night_shift_power': day_hourly[(day_hourly.index.hour >= 22) | (day_hourly.index.hour <= 6)]['avg_power'].mean(),\n",
    "                    \n",
    "                    # 운영 패턴 분석\n",
    "                    'peak_to_offpeak_ratio': day_hourly['avg_power'].max() / day_hourly['avg_power'].min() if day_hourly['avg_power'].min() > 0 else 0,\n",
    "                    'power_variability': day_hourly['avg_power'].std(),\n",
    "                    'power_skewness': stats.skew(day_hourly['avg_power']),\n",
    "                    \n",
    "                    # 연속 운영 지표\n",
    "                    'continuous_operation_hours': len(day_hourly[day_hourly['avg_power'] > day_hourly['avg_power'].quantile(0.7)]),\n",
    "                    'low_power_hours': len(day_hourly[day_hourly['avg_power'] < day_hourly['avg_power'].quantile(0.3)]),\n",
    "                    \n",
    "                    # 효율성 지표\n",
    "                    'power_efficiency_score': day_data['daily_total_power'] / (day_data['daily_avg_power'] * 24) if day_data['daily_avg_power'] > 0 else 0,\n",
    "                    \n",
    "                    # 시간대별 집중도\n",
    "                    'daytime_concentration': day_hourly[(day_hourly.index.hour >= 9) & (day_hourly.index.hour <= 18)]['avg_power'].sum() / day_data['daily_total_power'],\n",
    "                    'weekend_factor': 1 if date.weekday() >= 5 else 0,\n",
    "                    'month': date.month,\n",
    "                    'day_of_week': date.weekday()\n",
    "                }\n",
    "                \n",
    "                pattern_features.append(features)\n",
    "        \n",
    "        return pd.DataFrame(pattern_features)\n",
    "    \n",
    "    def create_time_lagged_features(self, pattern_df, production_df):\n",
    "        \"\"\"시간 지연 특성 생성 및 데이터 매칭\"\"\"\n",
    "        # 월별 생산지수 데이터 준비\n",
    "        production_df['date'] = pd.to_datetime(production_df['date'])\n",
    "        production_monthly = production_df.groupby([production_df['date'].dt.to_period('M')])['production_index'].mean().reset_index()\n",
    "        production_monthly['date'] = production_monthly['date'].dt.to_timestamp()\n",
    "        \n",
    "        # 전력 패턴 데이터를 월별로 집계\n",
    "        pattern_df['year_month'] = pd.to_datetime(pattern_df['date']).dt.to_period('M')\n",
    "        \n",
    "        monthly_patterns = pattern_df.groupby(['city', 'year_month']).agg({\n",
    "            'total_daily_power': 'mean',\n",
    "            'avg_daily_power': 'mean',\n",
    "            'morning_rush_power': 'mean',\n",
    "            'afternoon_peak_power': 'mean',\n",
    "            'night_shift_power': 'mean',\n",
    "            'peak_to_offpeak_ratio': 'mean',\n",
    "            'power_variability': 'mean',\n",
    "            'continuous_operation_hours': 'mean',\n",
    "            'power_efficiency_score': 'mean',\n",
    "            'daytime_concentration': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        monthly_patterns['date'] = monthly_patterns['year_month'].dt.to_timestamp()\n",
    "        \n",
    "        # 생산지수와 매칭\n",
    "        merged_data = pd.merge(monthly_patterns, production_monthly, on='date', how='inner')\n",
    "        \n",
    "        # 시간 지연 특성 생성 (1-3개월 선행지표)\n",
    "        for city in merged_data['city'].unique():\n",
    "            city_data = merged_data[merged_data['city'] == city].sort_values('date')\n",
    "            \n",
    "            # 1개월, 2개월, 3개월 후 생산지수\n",
    "            city_data['production_1m_future'] = city_data['production_index'].shift(-1)\n",
    "            city_data['production_2m_future'] = city_data['production_index'].shift(-2)\n",
    "            city_data['production_3m_future'] = city_data['production_index'].shift(-3)\n",
    "            \n",
    "            # 과거 패턴과의 비교\n",
    "            city_data['power_trend_1m'] = city_data['total_daily_power'].pct_change(1)\n",
    "            city_data['power_trend_3m'] = city_data['total_daily_power'].pct_change(3)\n",
    "            \n",
    "            merged_data.loc[merged_data['city'] == city, \n",
    "                          ['production_1m_future', 'production_2m_future', 'production_3m_future', \n",
    "                           'power_trend_1m', 'power_trend_3m']] = city_data[\n",
    "                ['production_1m_future', 'production_2m_future', 'production_3m_future',\n",
    "                 'power_trend_1m', 'power_trend_3m']].values\n",
    "        \n",
    "        return merged_data.dropna()\n",
    "    \n",
    "    def build_prediction_models(self, data):\n",
    "        \"\"\"다양한 예측 모델 구축\"\"\"\n",
    "        feature_columns = [\n",
    "            'total_daily_power', 'avg_daily_power', 'morning_rush_power',\n",
    "            'afternoon_peak_power', 'night_shift_power', 'peak_to_offpeak_ratio',\n",
    "            'power_variability', 'continuous_operation_hours', 'power_efficiency_score',\n",
    "            'daytime_concentration', 'power_trend_1m', 'power_trend_3m'\n",
    "        ]\n",
    "        \n",
    "        target_columns = ['production_1m_future', 'production_2m_future', 'production_3m_future']\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for target in target_columns:\n",
    "            print(f\"\\n=== {target} 예측 모델 ===\")\n",
    "            \n",
    "            # 데이터 준비\n",
    "            X = data[feature_columns]\n",
    "            y = data[target]\n",
    "            \n",
    "            # 시계열 분할\n",
    "            tscv = TimeSeriesSplit(n_splits=3)\n",
    "            \n",
    "            models = {\n",
    "                'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "                'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "                'Ridge': Ridge(alpha=1.0)\n",
    "            }\n",
    "            \n",
    "            target_results = {}\n",
    "            \n",
    "            for model_name, model in models.items():\n",
    "                cv_scores = []\n",
    "                feature_importances = []\n",
    "                \n",
    "                for train_idx, test_idx in tscv.split(X):\n",
    "                    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "                    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "                    \n",
    "                    # 스케일링\n",
    "                    X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "                    X_test_scaled = self.scaler.transform(X_test)\n",
    "                    \n",
    "                    # 모델 학습\n",
    "                    model.fit(X_train_scaled, y_train)\n",
    "                    \n",
    "                    # 예측 및 평가\n",
    "                    y_pred = model.predict(X_test_scaled)\n",
    "                    score = r2_score(y_test, y_pred)\n",
    "                    cv_scores.append(score)\n",
    "                    \n",
    "                    # 특성 중요도 (가능한 경우)\n",
    "                    if hasattr(model, 'feature_importances_'):\n",
    "                        feature_importances.append(model.feature_importances_)\n",
    "                \n",
    "                avg_score = np.mean(cv_scores)\n",
    "                avg_importance = np.mean(feature_importances, axis=0) if feature_importances else None\n",
    "                \n",
    "                target_results[model_name] = {\n",
    "                    'cv_score': avg_score,\n",
    "                    'cv_std': np.std(cv_scores),\n",
    "                    'feature_importance': dict(zip(feature_columns, avg_importance)) if avg_importance is not None else None\n",
    "                }\n",
    "                \n",
    "                print(f\"{model_name}: R² = {avg_score:.3f} (±{np.std(cv_scores):.3f})\")\n",
    "            \n",
    "            results[target] = target_results\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_temporal_relationships(self, data):\n",
    "        \"\"\"시간적 관계 분석\"\"\"\n",
    "        print(\"\\n=== 시간적 관계 분석 ===\")\n",
    "        \n",
    "        correlations = {}\n",
    "        \n",
    "        power_features = ['total_daily_power', 'morning_rush_power', 'night_shift_power', 'power_variability']\n",
    "        future_targets = ['production_1m_future', 'production_2m_future', 'production_3m_future']\n",
    "        \n",
    "        for power_feat in power_features:\n",
    "            correlations[power_feat] = {}\n",
    "            for target in future_targets:\n",
    "                corr = data[power_feat].corr(data[target])\n",
    "                correlations[power_feat][target] = corr\n",
    "                print(f\"{power_feat} vs {target}: {corr:.3f}\")\n",
    "        \n",
    "        return correlations\n",
    "    \n",
    "    def visualize_patterns(self, data, correlations):\n",
    "        \"\"\"패턴 시각화\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # 1. 전력 사용량 vs 생산지수 시계열\n",
    "        axes[0,0].plot(data['date'], data['total_daily_power'], label='Power Usage', alpha=0.7)\n",
    "        ax_twin = axes[0,0].twinx()\n",
    "        ax_twin.plot(data['date'], data['production_index'], label='Production Index', color='red', alpha=0.7)\n",
    "        axes[0,0].set_title('Power Usage vs Production Index Over Time')\n",
    "        axes[0,0].legend(loc='upper left')\n",
    "        ax_twin.legend(loc='upper right')\n",
    "        \n",
    "        # 2. 상관관계 히트맵\n",
    "        corr_matrix = pd.DataFrame(correlations).T\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0,1])\n",
    "        axes[0,1].set_title('Power-Production Correlation Matrix')\n",
    "        \n",
    "        # 3. 시간대별 전력 패턴\n",
    "        hourly_avg = data.groupby(data['date'].dt.hour).agg({\n",
    "            'morning_rush_power': 'mean',\n",
    "            'afternoon_peak_power': 'mean', \n",
    "            'night_shift_power': 'mean'\n",
    "        })\n",
    "        hourly_avg.plot(kind='bar', ax=axes[0,2])\n",
    "        axes[0,2].set_title('Average Power by Time Period')\n",
    "        axes[0,2].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # 4. 선행성 분석 - 산점도\n",
    "        axes[1,0].scatter(data['total_daily_power'], data['production_1m_future'], alpha=0.6)\n",
    "        axes[1,0].set_xlabel('Current Power Usage')\n",
    "        axes[1,0].set_ylabel('Production Index (1 month later)')\n",
    "        axes[1,0].set_title('Power Usage vs Future Production')\n",
    "        \n",
    "        # 5. 변동성 vs 생산성\n",
    "        axes[1,1].scatter(data['power_variability'], data['production_index'], alpha=0.6)\n",
    "        axes[1,1].set_xlabel('Power Variability')\n",
    "        axes[1,1].set_ylabel('Production Index')\n",
    "        axes[1,1].set_title('Power Variability vs Production')\n",
    "        \n",
    "        # 6. 효율성 지표\n",
    "        axes[1,2].scatter(data['power_efficiency_score'], data['production_index'], alpha=0.6)\n",
    "        axes[1,2].set_xlabel('Power Efficiency Score')\n",
    "        axes[1,2].set_ylabel('Production Index')\n",
    "        axes[1,2].set_title('Power Efficiency vs Production')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def generate_production_schedule_insights(self, data, model_results):\n",
    "        \"\"\"생산 스케줄 최적화 인사이트 생성\"\"\"\n",
    "        insights = {\n",
    "            'peak_efficiency_periods': {},\n",
    "            'optimal_power_patterns': {},\n",
    "            'schedule_recommendations': []\n",
    "        }\n",
    "        \n",
    "        # 최고 효율성 시간대 분석\n",
    "        high_efficiency = data[data['power_efficiency_score'] > data['power_efficiency_score'].quantile(0.8)]\n",
    "        \n",
    "        insights['peak_efficiency_periods'] = {\n",
    "            'morning_rush_avg': high_efficiency['morning_rush_power'].mean(),\n",
    "            'afternoon_peak_avg': high_efficiency['afternoon_peak_power'].mean(),\n",
    "            'night_shift_avg': high_efficiency['night_shift_power'].mean(),\n",
    "            'optimal_variability': high_efficiency['power_variability'].mean()\n",
    "        }\n",
    "        \n",
    "        # 최적 전력 패턴\n",
    "        high_production = data[data['production_index'] > data['production_index'].quantile(0.8)]\n",
    "        \n",
    "        insights['optimal_power_patterns'] = {\n",
    "            'target_daily_power': high_production['total_daily_power'].mean(),\n",
    "            'target_peak_ratio': high_production['peak_to_offpeak_ratio'].mean(),\n",
    "            'target_continuous_hours': high_production['continuous_operation_hours'].mean()\n",
    "        }\n",
    "        \n",
    "        # 스케줄 추천\n",
    "        insights['schedule_recommendations'] = [\n",
    "            f\"최적 일일 전력 사용량: {insights['optimal_power_patterns']['target_daily_power']:.0f} kWh\",\n",
    "            f\"권장 연속 운영 시간: {insights['optimal_power_patterns']['target_continuous_hours']:.1f}시간\",\n",
    "            f\"최적 피크/오프피크 비율: {insights['optimal_power_patterns']['target_peak_ratio']:.2f}\",\n",
    "            f\"모닝 러시 시간대 목표 전력: {insights['peak_efficiency_periods']['morning_rush_avg']:.0f} kWh\"\n",
    "        ]\n",
    "        \n",
    "        return insights\n",
    "\n",
    "# 실행 함수\n",
    "def main():\n",
    "    print(\"=== 전력 패턴 기반 제조업 생산지수 예측 분석 ===\")\n",
    "    \n",
    "    # MySQL 연결 (실제 연결 정보로 변경 필요)\n",
    "    connection_string = \"mysql+mysqlconnector://root:1234@localhost/manufacturing_insight\"\n",
    "    \n",
    "    analyzer = PowerProductionAnalyzer(connection_string)\n",
    "    \n",
    "    try:\n",
    "        # 1. 데이터 로드\n",
    "        print(\"\\n1. 데이터 로드 중...\")\n",
    "        # power_df, production_df = analyzer.load_and_merge_data()\n",
    "        \n",
    "        # 2. 전력 패턴 특성 추출\n",
    "        print(\"2. 전력 사용 패턴 분석 중...\")\n",
    "        # pattern_df = analyzer.extract_power_patterns(power_df)\n",
    "        \n",
    "        # 3. 시간 지연 특성 생성\n",
    "        print(\"3. 시간적 관계 분석용 데이터 준비 중...\")\n",
    "        # merged_data = analyzer.create_time_lagged_features(pattern_df, production_df)\n",
    "        \n",
    "        # 4. 예측 모델 구축\n",
    "        print(\"4. 예측 모델 학습 중...\")\n",
    "        # model_results = analyzer.build_prediction_models(merged_data)\n",
    "        \n",
    "        # 5. 시간적 관계 분석\n",
    "        print(\"5. 시간적 관계 분석 중...\")\n",
    "        # correlations = analyzer.analyze_temporal_relationships(merged_data)\n",
    "        \n",
    "        # 6. 시각화\n",
    "        print(\"6. 결과 시각화 중...\")\n",
    "        # fig = analyzer.visualize_patterns(merged_data, correlations)\n",
    "        # plt.show()\n",
    "        \n",
    "        # 7. 생산 스케줄 최적화 인사이트\n",
    "        print(\"7. 생산 스케줄 최적화 인사이트 생성 중...\")\n",
    "        # insights = analyzer.generate_production_schedule_insights(merged_data, model_results)\n",
    "        \n",
    "        print(\"\\n=== 분석 완료 ===\")\n",
    "        print(\"실제 데이터를 로드하여 실행하세요!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        print(\"MySQL 연결 정보와 테이블 구조를 확인해주세요.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
